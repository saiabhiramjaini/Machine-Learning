
# Naive Bayes

## Introduction
Naive Bayes is a probabilistic machine learning algorithm used for classification tasks. It is based on Bayes' Theorem and is particularly suited for text classification problems. The algorithm is called "naive" because it makes the assumption that the features are conditionally independent, which is rarely true in real-life scenarios. Despite this assumption, Naive Bayes often performs well in practice.

## Bayes' Theorem
Bayes' Theorem provides a way to update the probability of a hypothesis based on new evidence. The formula is:

![image](https://github.com/saiabhiramjaini/portfolio/assets/115941546/9c64e3fa-234e-44ae-bef2-476d81aecc9e)

## Naive Bayes Classifier
In the context of classification, we use Bayes' Theorem to calculate the probability of each class given the input features and then choose the class with the highest probability.


### Types of Naive Bayes Classifiers
There are three main types of Naive Bayes classifiers, each suited for different types of data:

**1. Gaussian Naive Bayes**:
   - Used when the features are continuous and assumed to follow a Gaussian (normal) distribution.
   - The probability is calculated using the Gaussian distribution formula.

**2. Multinomial Naive Bayes**:
   - Used for discrete data, such as word counts in text classification.
   - It assumes that the features follow a multinomial distribution.

**3. Bernoulli Naive Bayes**:
   - Used for binary/boolean features, where each feature is either present or absent.
   - It assumes that the features follow a Bernoulli distribution.


## How Naive Bayes Works
**1. Training**:
   - Calculate the prior probability for each class.
   - Calculate the likelihood of each feature given each class.
   - Store these probabilities for use in classification.

**2. Classification**:
   - For a given input, calculate the posterior probability for each class using Bayes' Theorem.
   - Choose the class with the highest posterior probability.



## Understanding with an Example


Let's assume there are people who commute to their office in two different ways: by walking or by driving. Each person has attributes such as **salary** and **age**. We can visualize this scenario on a scatter plot where:

- The x-axis represents the **Age** of the person.
- The y-axis represents the **Salary** of the person.
- Red crosses (`+`) represent people who **walk** to work.
- Green plus signs (`+`) represent people who **drive** to work.

![image](https://github.com/saiabhiramjaini/portfolio/assets/115941546/9a08dc6a-d391-48e5-935c-4caf23bd999a)

Now when a new datapoint gets added how to classify that?

![image](https://github.com/saiabhiramjaini/portfolio/assets/115941546/65909880-bfd2-4353-9dd5-5890a7f08cd3)

![image](https://github.com/saiabhiramjaini/portfolio/assets/115941546/026d8c93-d557-46ff-be37-ba42c830478f)

![image](https://github.com/saiabhiramjaini/portfolio/assets/115941546/9e0772c8-d0ee-4878-9706-38b6c990aae0)


Here X represents the features of a class.

![image](https://github.com/saiabhiramjaini/portfolio/assets/115941546/71873ec1-1067-48c0-8602-2a0385f5be7a)

After that to calculate P(X) we will consider a circular area with new datapoint as center of any radius as shown in the figure.

Now we assume that all the points inside that cirecle are similar.

No. of points inside the circle = Number of similar observations = 4

![image](https://github.com/saiabhiramjaini/portfolio/assets/115941546/8dc7e299-fd97-4711-90a4-a01bf9959ef5)

Now to calculate likelihood i.e. how likely a person with X features will walk we consider the same circle, but only data points that are representing 'walk' are considered.

![image](https://github.com/saiabhiramjaini/portfolio/assets/115941546/bf571371-b3b9-481a-9775-6883a270dfa4)

![image](https://github.com/saiabhiramjaini/portfolio/assets/115941546/31a2489a-c3e1-4841-bae6-5442586fe6bf)

Now perform similar calculations for class Drive

![image](https://github.com/saiabhiramjaini/portfolio/assets/115941546/74fd2a95-5b1f-4616-a38a-c039dbe40c3a)


Finally the probability of walk > probability of drive. So, the new datapoint is classified under walk.





