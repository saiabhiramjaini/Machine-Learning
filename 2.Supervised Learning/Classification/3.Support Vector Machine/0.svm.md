
# Support Vector Machine (SVM)

## Introduction
Support Vector Machine (SVM) is a supervised machine learning algorithm used for both classification and regression tasks. However, it is primarily used for classification problems. The goal of the SVM algorithm is to find a hyperplane in an N-dimensional space (N â€” the number of features) that distinctly classifies the data points.

## Key Concepts

**Hyperplane**:
A hyperplane is a decision boundary that separates the data points of different classes. In 2D, it's a line, but in higher dimensions, it becomes a plane or a hyperplane.

**Support Vectors**:
Support vectors are the data points that are closest to the hyperplane. These points are critical in defining the position and orientation of the hyperplane. The SVM algorithm aims to find the hyperplane that maximizes the margin, which is the distance between the hyperplane and the nearest support vectors.

**Margin**:
The margin is the distance between the hyperplane and the nearest support vector from either class. A larger margin is considered better as it indicates a more confident classification.

![image](https://i.pinimg.com/564x/95/fd/e5/95fde5edf0d84f99011ee858bfbfbef5.jpg)

## Types of SVM

**Linear SVM**:
Linear SVM is used when the data can be linearly separated. In other words, it can classify the data points with a straight line (in 2D) or a hyperplane (in higher dimensions).

**Non-Linear SVM**:
When data cannot be separated by a straight line, Non-Linear SVM comes into play. It uses kernel functions to transform the data into a higher dimension where a hyperplane can be used to separate the classes.

![image](https://i1.wp.com/cmdlinetips.com/wp-content/uploads/2021/02/Linearly_Separable_Data_Example.png?fit=539,234&ssl=1)


## Understanding SVM 

Let's assume there are two classes plotted in the image below. To separate them, we need to choose a line. There are two lines in the image, one red and one green. Which line should we choose?

![image](https://github.com/saiabhiramjaini/portfolio/assets/115941546/285ceb33-f44f-48d6-bb2e-5c2581a75440)

The answer is the green line.


- **Red Line**: The red line separates the two classes but with a smaller margin. The closest data points (support vectors) are nearer to the decision boundary.
- **Green Line**: The green line also separates the two classes but with a larger margin. The support vectors are farther from the decision boundary compared to the red line.

![image](https://github.com/saiabhiramjaini/portfolio/assets/115941546/e4719b96-d0cd-430d-bfb0-bd8d6bc1fa3a)

A larger margin means the classifier is more robust to noise and variability in the data. It reduces the risk of misclassifying future data points that are close to the decision boundary.
