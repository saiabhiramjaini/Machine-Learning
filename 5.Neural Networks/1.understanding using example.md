# Understanding Neural network through an example:

- Now we need to train a model that detects shape i.e. circle or square or triangle. 


![image](https://github.com/user-attachments/assets/7c32bbad-4999-401f-bf33-905b0bc9071c)


- In a neural network we will have an **input layer which receives an input.** 

- **Output layer will predict.**

- **Hidden layers will perform computation.**

- Now let us consider a circle image of 28 X 28 pixels so total pixels are 784(28*28) 

- These 784 pixels are given as input for the input layer of neural network. 

![image](https://github.com/user-attachments/assets/82de8ba5-a733-4711-83bd-e2aa32ac5203)

- Neurons of one layer are connected to another layer through channels, these channels are assigned with a numerical value called as weights. 

- The **weight of a neuron tells us how important the neuron is, higher weight means higher importance.** 

- **Inputs are multiplied with their weights and their sum is sent as input to neurons in hidden layer, where each neuron is associated with a numeric value called bias.**

![image](https://github.com/user-attachments/assets/2c26ddc2-8ee5-403e-a830-b3c77300e60d)

- Now the weighted sum is added to bias. 

- The result of the **activation function will determine whether a particular neuron gets activated or not.** 

- An **activated neuron will pass their output as input to next layer** through channels. 


![image](https://github.com/user-attachments/assets/5cf53aac-d63a-49ee-b58d-73722d4d99c7)

- In this manner data is propagated through a network. 

- This is called **forward propagation.**

![image](https://github.com/user-attachments/assets/3364ea89-a7e7-4544-a594-bc408c4c52ed)

- In the **output layer, the neuron with highest value will fire and determines the output.** 

![image](https://github.com/user-attachments/assets/435a5b5f-5d47-4435-9dde-f4d0ecdb88b0)

- Let us assume that the output is square, but it is not true, now the question is how the network figure will it out that the prediction is not correct. 

![image](https://github.com/user-attachments/assets/94fafd8e-178a-4a1a-a2d0-e3cd2a7a0f30)


- It is to be noted that our training is not done yet. 

- During the training process along with the input our network also has the output fed to it. 

- The **predicted output is compared with actual output to realize the error in prediction.** 

- The magnitude of error will indicate how wrong we are, and the sign suggests if our predicted values are higher or lower than expected. 

![image](https://github.com/user-attachments/assets/d488d266-f23a-4e4d-9c09-dcfb7d0fb184)

- The arrows here indicate the change in magnitude to reduce the error. 

- This information is now transferred back to the neural network which is termed as **backpropagation.** 

- Back propagation is one of the reason why neural networking is so powerful, it is the reason for why neural networks can learn from themselves. 

- During this process **weights and biases** get altered such that the network gives us correct prediction. (observe the weights in below image) 

![image](https://github.com/user-attachments/assets/365a3ea5-3e14-4ac0-839d-d69ca96e602b)

![image](https://github.com/user-attachments/assets/23bf4285-6730-440f-a9d7-6fb86f14f069)

- This **cycle of forward propagation and backpropagation** will be performed iteratively till the weights are assigned such that the network can predict correct output. 

- This brings the training process to an end. 