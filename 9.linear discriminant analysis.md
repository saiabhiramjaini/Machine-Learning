
# Linear Discriminant Analysis (LDA)

Linear Discriminant Analysis (LDA) is one of the commonly used dimensionality reduction techniques in machine learning to solve more than two-class classification problems. It is also known as Normal Discriminant Analysis (NDA) or Discriminant Function Analysis (DFA).

This can be used to project the features of higher dimensional space into lower-dimensional space in order to reduce resources and dimensional costs. 

Although the logistic regression algorithm is limited to only two-class, linear Discriminant analysis is applicable for more than two classes of classification problems.

Linear Discriminant analysis is one of the most popular dimensionality reduction techniques used for supervised classification problems in machine learning. 

## Example

Let's assume we have to classify two different classes having two sets of data points in a 2-dimensional plane as shown below image:

![image](https://github.com/saiabhiramjaini/portfolio/assets/115941546/13c52906-e3e5-4779-b82e-5e5f94f4c2a8)

However, it is impossible to draw a straight line in a 2-d plane that can separate these data points efficiently but using linear Discriminant analysis; we can dimensionally reduce the 2-D plane into the 1-D plane.

Linear Discriminant analysis is used as a dimensionality reduction technique in machine learning, using which we can easily transform a 2-D and 3-D graph into a 1-dimensional plane.

Let's consider an example where we have two classes in a 2-D plane having an X-Y axis, and we need to classify them efficiently. Here, LDA uses an X-Y axis to create a new axis by separating them using a straight line and projecting data onto a new axis.

Hence, we can maximize the separation between these classes and reduce the 2-D plane into 1-D.

![image](https://github.com/saiabhiramjaini/portfolio/assets/115941546/54a7faf5-3898-4b21-b187-b93ace85dd40)

To create a new axis, Linear Discriminant Analysis uses the following criteria:

- It maximizes the distance between means of two classes.
- It minimizes the variance within the individual class.

Using the above two conditions, LDA generates a new axis in such a way that it can maximize the distance between the means of the two classes and minimizes the variation within each class.

In other words, we can say that the new axis will increase the separation between the data points of the two classes and plot them onto the new axis.

## Advantages of LDA

- **Dimensionality Reduction**: Reduces the number of features while preserving class-discriminatory information.
- **Improved Performance**: Can enhance the performance of classifiers by removing noise and redundant features.
- **Simplicity**: LDA is simple to implement and interpret.

## Limitations of LDA

- **Linearity**: Assumes linear decision boundaries which may not be suitable for complex datasets.
- **Scalability**: May not perform well with very large datasets or high-dimensional data.

## Applications of LDA

- **Face Recognition**: Reducing the dimensionality of facial images for classification.
- **Medical Diagnosis**: Classifying diseases based on diagnostic features.
- **Marketing**: Customer segmentation and behavior prediction.
